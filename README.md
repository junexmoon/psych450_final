
**Abstract**
This report discusses the current methods used in detecting breast cancer, the application of convolution neural networks to aiding pathology, and my proposed model to this field. Specifically, the paper discusses the current shortcomings of manually examining biopsied cell specimens on slides and how the advent of machine learning to oncology and pathology has expedited these normally laborious and time-intensive processes. The proposed binary classification model would exemplify how machine learning can emulate the diagnostic process but in a much faster way. The methods and reasoning by which the model is made to learn from the training data and improve its predictions is also discussed. Then, the potential future direction of the model, a reflection on alternative approaches I could have had with building the model, as well as real life applications of neural networks in pathology are discussed. 

**Introduction** 
For women in the United States, breast cancer is currently the second most diagnosed type of cancer and the second leading cause of cancer-related death. Presently, the average woman in the United States has a 1 in 8 chance of developing breast cancer in her lifetime (American Cancer Society, 2021). There are several methods by which physicians diagnose breast cancer: Breast ultrasounds, diagnostic mammograms, Magnetic Resonance Imaging (MRIs), and biopsies (Center for Disease Control, 2021). Of the several methods, the one which is almost always used to make an official diagnosis is via biopsy. Biopsies occur when a sample of tissue is taken from a patient to test; the specimen is analyzed under a microscope by pathologists to determine whether or not the specimen is actually cancerous as well as to determine any other information about the cancer type and grade. Unusual lumps or tumors are oftentimes not cancerous though, so these biopsies offer more critical diagnostic information that is otherwise unavailable via ultrasounds, mammograms, or MRIs (American Cancer Society, 2021). In a biopsy, individual cells, cell nucleuses, and cell clusters will be examined for characteristics that indicate cancer. Cell nuclei are an important facet of diagnosis because of the way their features can distinguish a cancerous cell from a noncancerous cell. Typically, cancerous cell nuclei will be larger and darker and more size-variant than a non-cancerous cell. Once stained, cancerous cell nuclei will also appear darker in color. The reason for their darker, larger appearance is due to the fact that cancerous cells generally contain excess DNA (American Cancer Society, 2021). The current standard for breast cancer diagnosis is by examination of specimens on slides, where cells are stained and analyzed by pathologists. This process generally takes  1-2 weeks and is followed by an official pathology report and diagnosis. However, this process is time-consuming, labor intensive, and largely dependent on the availability of experienced pathologists, making it an inefficient and oftentimes stress-inducing process for urgent patients waiting to get a diagnosis (Gurcan et al., 2009). Recently, there has been a trend in the automation and digitization of the cancer diagnostic process, with a particular interest in the application of artificial intelligence to expedite and optimize diagnoses. In particular, researchers and scientists specializing in artificial intelligence have been utilizing convolutional neural networks and their deep learning algorithms for their classification and diagnosis prediction capabilities (Bera et al., 2019). The processing of diagnosing a disease is a form of classification; from a biological standpoint, pathologists’ brains have learned to recognize and differentiate cancerous cells from noncancerous cells by learning; they begin by drawing associations between cancerous cells’ characteristics, drawing out the patterns of the data that make them unique to noncancerous cells. Through a process of trial and error, the neurons and connections between the neurons associated with the memory or recognition of these cell characteristics become appropriately strengthened or weakened as the budding pathologist receives feedback from their environment about whether or not the diagnosis is correct. A convolutional neural network mimics the processes of natural learning, but with less time and cost but comparable —and even better— accuracy so that these diagnoses can be made after training networks on previous, real life data. From the training data, it can learn to make diagnoses from data collected during biopsy, hence why convolutional neural networks have been increasingly applicable in cancer diagnosis. 

**Description of Model**

Network Overview

For my network, I proposed a convolutional neural network capable of classifying a patient’s cell as benign (noncancerous) or malignant (cancerous) given that cell nucleus’s attributes. In real life application, a pathologist could record quantitative measurements about attributes of a cell nucleus as they would in a standard biopsy, but apply the convolution neural network so that from the data, it could make a prediction about whether or not the cell was malignant. Because the model has to classify cells as being either malignant or benign, the network would be a binary classification model because there are only two classifications for the output.

[Figure 1. Model showing Malignant (left column) or Benign (right column) output](img/fig1.png)
Figure 1 shows how by looking at the NetView in the simulation, the model would indicate a malignant diagnosis via activation in the first column. While the model would ideally learn to predict a diagnosis with a high degree of accuracy, I imagine that the neural network would be supplemented with a pathologist’s own analysis and subsequent diagnosis, but that the prediction would be utilized in part to expedite the whole diagnostic process.

Dataset 

Before I finalized what my model would do, I knew that I wanted to create some sort of classification neural network to aid in disease diagnosis. Knowing that the output would have to do with diagnosing a certain disease, I began thinking about the potential data’s attributes as a list of symptoms. After initially thinking of creating my own dataset, I realized that it would require a lot of manual inputs, which would be quite time consuming and not as accurate as a published dataset. Considering that models are more effective when larger amounts of data better enable it to produce more accurate relationships, I knew that this would not be an ideal decision. Eventually, I ended up using the University of California, Irvine (UCI) Machine Learning Repository to look for datasets and found the Wisconsin Breast Cancer Database.
The Wisconsin Breast Cancer Database has multiple datasets, but the one that I chose had a record of over 500 real patients’ data taken from biopsies of their tumor cell nuclei. The dataset shows the patient’s ID number, whether the patient’s tumor was malignant or benign, as well as ten features of cell nucleuses. The data has 32 attributes; the first two are the patient ID and Diagnosis (with M=Malignant and B=Benign). The following 30 are the mean, standard error, and largest values of the cell nucleus’ Radius (mean of distances from center to points on the perimeter), Texture (standard deviation of gray-scale values), Perimeter, Area, Smoothness (local variation in radius lengths), Compactness (perimeter^2 / area - 1.0), Concavity (severity of concave portions of the contour), Concave points (number of concave portions of the contour), Symmetry, and Fractal dimension ("coastline approximation" - 1). Within the data, every tenth column indicates an attribute’s mean, standard error, and texture so that the mean of Radius would be attribute #3, standard deviation of Radius #13, and the largest value of Radius #23.
In addition, I changed the dataset slightly so it would be better understood by and applied to the model. The original dataset had a single column for the diagnosis, indicating a “B” for benign and “M” for malignant. I changed this by creating two columns, where one column would indicate a “1” for malignant and “0” for benign while the other column would indicate “0” for malignant and “1” for benign. I also normalized all the values by dividing every value by the highest value found in the overall dataset. This actually proved to create major formatting difficulties when transferring the data from Excel to csv due to the conversion to scientific notation but was resolved by manually changing the formatting settings.

Proposed Network Structure

My model would consisten of an input layer, one hidden layer, and an output layer. Each layer would be a 2D layer. Because the dataset has 30 attributes, the input layer would be a 1x30 layer, where each node represents an attribute in the dataset; for example, the first node would be the mean of the nuclei radius. I initially proposed my hidden layer consist of a number of nodes between the quantity of nodes in the input layer and the nodes in the output layer. Since my output layer would have two nodes, one for each type of diagnosis, I knew I wanted to start with a number between 2 and 30. I chose to have 16 nodes in a 2x8 format to start, and would eventually adjust the size of the hidden layer as I worked with my model. Knowing that I was going to use a mix of Hebbian and Error-Driven learning for my network, I established feedforward connections between the input and hidden layers as well as bidirectional connectivity between the hidden and output layers to allow for backpropagation. I structured the network in this way because I wanted the model to learn to make some associations between the different attributes but also be able to “correct” itself.  Specifically, I created my model based off of the source code from the hebberr_combo sim because I wanted to utilize the network configurations as well as the Hebbian/Error-Driven learning combination established in that network. From there, I would tweak the dataset and parameters to fit my own project’s needs.

Process and Method

For my model, I began by using the hebber_combo sim as the model, adapting its default parameters but changing the network configurations by changing the hidden layer nodes. I started off by creating a 2x8 hidden layer.

[Figure 2. TrnEpcPlot and TrnEpcPlot for initial model](img/fig2log.png) (img/fig2plot.png)
According to Figure 2, my network started at a PctCor rate of less than half, but hovered at around the 50% mark for the entire training run. This indicated that the network wasn’t learning, but instead making guesses. I began adjusting the network by trying variations of the number of hidden layer nodes, until deciding upon a 10x30 hidden layer structure. While this created for some slight improvement, the change was not drastic enough so I began adjusting some parameters. I began by changing the learning factors, testing each one and then combinations by turning them on or off. After changing the learning factors so that norm, momentum, and wtbal were all applied, my network saw a drastic change.


[Figure 3. TrnEpcPlot and TrnEpcPlot after applying 10x30 hidden layer](img/fig3log.png) (img/fig3plot.png)
As seen in Figure 3, turning on these learning factors made it so that my network was showing evident signs of learning, moving up to a maximum 74% correct rate during a training run. I tried adjusting some other parameters, such as the average activation levels or learning strength factors. Making changes to these parameters resulted in either worse or similar rates of correctness, with what seemed to be a ceiling at the 74% mark. Later, I began tweaking inhibition levels as well to see if there would be any effect. I lowered it slightly and saw that this 74% “ceiling” had been broken, moving it up slightly. I lowered it quite drastically until it reached a maximum 76% correct rate.


[Figure 4. TrnEpcPlot and TrnEpcPlot after lowering inhibition](img/fig4log.png) (img/fig4plot.png)
After achieving this 76% correct rate in Figure 4, I hit another “ceiling”, unable to move past this 76% maximum correct rate. Even after adjusting all the parameters and even trying to add some, such an excitation, there did not seem to be a difference. I tried going back to my network configurations to try and attempt a change in the nodes but again, 10x30 seemed to be the most optimal. I then tried a 4D hidden layer to see if there would be an effect. I attempted a few variations of nodes, and settled upon a 2x4x5x6 hidden layer after breaking this second ceiling, and reaching a 77% maximum correct rate.


[Figure 5. TrnEpcPlot and TrnEpcPlot after changing 2D hidden layer into 4D hidden layer](img/fig5log.png) (img/fig5plot.png)
After attempting to adjust the parameters with this 4D layer and even trying to add another hidden layer (and trying variations of combining multiple 2D or 4D hidden layers), I found that I could not achieve a correct rate higher than this 77%. Overall, the general trend of learning also remained fairly consistent no matter how much I adjusted the parameters or slightly reconfigured the network with the limited sections of code I knew how to change, which makes me believe that while these slight changes could result in some learning improvements, the network may need some larger structural changes in order to break this general correctness rate ceiling. However, because of my limited programming experience, I thought this to be slightly outside the scope of this project. 

**Discussion**

Future Changes

In the future, I would like to have explored using different base simulations to see how that would have improved the learning rate. Ideally, I would like to increase the accuracy of the model so that when it learns, it can reliably have a 90%+ correct response rate. I think I would look into using the ra25 model or the err_driven_hidden sim to see if the network structure would be better for my model. In addition to trying out these other base models, I would also like to expand my model to be able to predict grading. Tumor grading occurs after a cancer diagnosis is made, in which the cells of a tumor are examined to determine how likely they are to grow and spread (National Cancer Institute, 2021)). While breast cancer staging requires other factors, nuclear grade, which involves evaluating the tumor cell’s nucleus size and shape, could be evaluated as a part of the network. I believe I would explore adding another output layer and hidden layer that would predict the grade of the tumor.

Application of Model

The application of convolutional neural networks to the field of pathology and oncology has immense potential and growth trajectory. Considering that artificial intelligence is already being used in the diagnostic process, I believe that my model, if improved, could be applied alongside pathology reports to supplement a pathologist’s own analysis and diagnosis. One of the biggest limitations of my model is that it wasn’t able to achieve a high learning rate, although I do believe that could be solved eventually by reconfiguring the structure and parameters of the network a bit more. I also believe that the field of pathology innately requires human input; considering the stakes of cancer diagnoses, I believe that real doctors will continue to use neural networks as a supplement to their own analysis because they have the advantage of their own intuition as well as access to other information (either related to the patient or the disease) that can influence their diagnosis decision. 

